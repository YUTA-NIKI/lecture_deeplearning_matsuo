{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chap06_homework.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YUTA-NIKI/lecture_deeplearning_matsuo/blob/master/chap06_homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PejyCV2Krxk",
        "colab_type": "code",
        "outputId": "22178007-7d2e-4aeb-ecc2-64613836ccac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj7Ux-oZLE6-",
        "colab_type": "code",
        "outputId": "8e23e129-8f4c-4c7c-8b4c-288dcb8c7571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls \"/content/drive/My Drive/lecture_master/2019_summer/deeplearning_matsuo/data/chap06\"\n",
        "data_path = \"/content/drive/My Drive/lecture_master/2019_summer/deeplearning_matsuo/data/chap06\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t_train.npy  x_test.npy  x_train.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNfTmpxVLLUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "try:\n",
        "    del [\n",
        "        tf.app,\n",
        "        tf.compat,\n",
        "        tf.contrib,\n",
        "        tf.estimator,\n",
        "        tf.gfile,\n",
        "        tf.graph_util,\n",
        "        tf.image,\n",
        "        tf.initializers,\n",
        "        tf.keras,\n",
        "        tf.layers,\n",
        "        tf.logging,\n",
        "        tf.losses,\n",
        "        tf.metrics,\n",
        "        tf.python_io,\n",
        "        tf.resource_loader,\n",
        "        tf.saved_model,\n",
        "        tf.sets,\n",
        "        tf.summary,\n",
        "        tf.sysconfig,\n",
        "        tf.test\n",
        "    ]\n",
        "    \n",
        "except AttributeError:\n",
        "    print('Unrequired modules are already deleted (Skipped).')\n",
        "\n",
        "def load_mnist():\n",
        "\n",
        "    # 学習データ\n",
        "    x_train = np.load(os.path.join(data_path,'x_train.npy'))\n",
        "    t_train = np.load(os.path.join(data_path,'t_train.npy'))\n",
        "    \n",
        "    # テストデータ\n",
        "    x_test = np.load(os.path.join(data_path,'x_test.npy'))\n",
        "\n",
        "    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "    x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "    t_train = np.eye(10)[t_train.astype('int32').flatten()]\n",
        "\n",
        "    return (x_train, x_test, t_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b6vOm3JbLt8",
        "colab_type": "text"
      },
      "source": [
        "Optimizer: SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5axro-KbL4OB",
        "colab_type": "code",
        "outputId": "8b571c1b-1543-4f9e-94ac-94989c75b376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rng = np.random.RandomState(1234)\n",
        "random_state = 42\n",
        "\n",
        "### レイヤー定義 ###\n",
        "\n",
        "class Conv:\n",
        "    def __init__(self, filter_shape, function=lambda x: x, strides=[1,1,1,1], padding='VALID'):\n",
        "        \n",
        "        fan_in  = np.prod(filter_shape[:3])\n",
        "        fan_out = np.prod(filter_shape[:2]) * filter_shape[3]\n",
        "        \n",
        "        self.W = tf.Variable(rng.uniform(\n",
        "            low=-np.sqrt(6/fan_in),\n",
        "            high=np.sqrt(6/fan_in),\n",
        "            size=filter_shape\n",
        "        ).astype('float32'), name='W')\n",
        "        self.b = tf.Variable(np.zeros((filter_shape[3]), dtype='float32'), name='b')\n",
        "        self.function = function\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        u = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding) + self.b\n",
        "        return self.function(u)\n",
        "    \n",
        "    \n",
        "class Pooling:\n",
        "    def __init__(self, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID'):\n",
        "        self.ksize = ksize\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return tf.nn.max_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding)\n",
        "    \n",
        "    \n",
        "class Flatten:\n",
        "    def __call__(self, x):\n",
        "        return tf.reshape(x, (-1, np.prod(x.get_shape().as_list()[1:])))\n",
        "    \n",
        "    \n",
        "class Dense:\n",
        "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
        "        \n",
        "        self.W = tf.Variable(rng.uniform(\n",
        "            low=-np.sqrt(6/in_dim),\n",
        "            high=np.sqrt(6/in_dim),\n",
        "            size=(in_dim, out_dim)\n",
        "        ).astype('float32'), name='W')\n",
        "        self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))\n",
        "        self.function = function\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return self.function(tf.matmul(x, self.W) + self.b)\n",
        "    \n",
        "    \n",
        "def tf_log(x):\n",
        "    return tf.log(tf.clip_by_value(x, 1e-10, x))\n",
        "    \n",
        "### ネットワーク ###\n",
        "\n",
        "x_train, x_test, t_train = load_mnist()\n",
        "x_train, x_valid, t_train, t_valid = train_test_split(x_train, t_train, test_size=0.1, random_state=random_state)\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "t = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "h = Conv((5, 5, 1, 20), tf.nn.relu)(x)\n",
        "h = Pooling((1, 2, 2, 1))(h)\n",
        "h = Conv((5, 5, 20, 50), tf.nn.relu)(h)\n",
        "h = Pooling((1, 2, 2, 1))(h)\n",
        "h = Flatten()(h)\n",
        "y = Dense(4*4*50, 10, tf.nn.softmax)(h)\n",
        "\n",
        "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1))\n",
        "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
        "\n",
        "### 学習 ###\n",
        "\n",
        "n_epochs = 10\n",
        "batch_size = 100\n",
        "n_batches = x_train.shape[0]//batch_size\n",
        "\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    x_train, t_train = shuffle(x_train, t_train)\n",
        "    for batch in range(n_batches):\n",
        "        start = batch * batch_size\n",
        "        end = start + batch_size\n",
        "        sess.run(train, feed_dict={x: x_train[start:end], t: t_train[start:end]})\n",
        "            \n",
        "    y_pred, cost_valid = sess.run([y, cost], feed_dict={x: x_valid, t: t_valid})\n",
        "        \n",
        "    print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
        "        epoch,\n",
        "        cost_valid,\n",
        "        accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "    ))\n",
        "# y_pred = sess.run(y, feed_dict={x: x_test})\n",
        "# submission = pd.Series(y_pred.argmax(axis=1), name='label')\n",
        "# submission.to_csv('/content/drive/My Drive/lecture_master/2019_summer/deeplearning_matsuo/homework/chap06/submission_pred.csv', header=True, index_label='id')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "EPOCH: 0, Valid Cost: 0.588, Valid Accuracy: 0.783\n",
            "EPOCH: 1, Valid Cost: 0.501, Valid Accuracy: 0.820\n",
            "EPOCH: 2, Valid Cost: 0.467, Valid Accuracy: 0.830\n",
            "EPOCH: 3, Valid Cost: 0.440, Valid Accuracy: 0.845\n",
            "EPOCH: 4, Valid Cost: 0.426, Valid Accuracy: 0.852\n",
            "EPOCH: 5, Valid Cost: 0.402, Valid Accuracy: 0.857\n",
            "EPOCH: 6, Valid Cost: 0.393, Valid Accuracy: 0.860\n",
            "EPOCH: 7, Valid Cost: 0.390, Valid Accuracy: 0.861\n",
            "EPOCH: 8, Valid Cost: 0.374, Valid Accuracy: 0.865\n",
            "EPOCH: 9, Valid Cost: 0.372, Valid Accuracy: 0.865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zovMQ3vvbTIO",
        "colab_type": "text"
      },
      "source": [
        "Optimizer: Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC0QXs5eZnjA",
        "colab_type": "code",
        "outputId": "24e0ac33-a64d-4123-c604-029fd224dc2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rng = np.random.RandomState(1234)\n",
        "random_state = 42\n",
        "\n",
        "### レイヤー定義 ###\n",
        "\n",
        "class Conv:\n",
        "    def __init__(self, filter_shape, function=lambda x: x, strides=[1,1,1,1], padding='VALID'):\n",
        "        \n",
        "        fan_in  = np.prod(filter_shape[:3])\n",
        "        fan_out = np.prod(filter_shape[:2]) * filter_shape[3]\n",
        "        \n",
        "        self.W = tf.Variable(rng.uniform(\n",
        "            low=-np.sqrt(6/fan_in),\n",
        "            high=np.sqrt(6/fan_in),\n",
        "            size=filter_shape\n",
        "        ).astype('float32'), name='W')\n",
        "        self.b = tf.Variable(np.zeros((filter_shape[3]), dtype='float32'), name='b')\n",
        "        self.function = function\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        u = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding) + self.b\n",
        "        return self.function(u)\n",
        "    \n",
        "    \n",
        "class Pooling:\n",
        "    def __init__(self, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID'):\n",
        "        self.ksize = ksize\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return tf.nn.max_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding)\n",
        "    \n",
        "    \n",
        "class Flatten:\n",
        "    def __call__(self, x):\n",
        "        return tf.reshape(x, (-1, np.prod(x.get_shape().as_list()[1:])))\n",
        "    \n",
        "    \n",
        "class Dense:\n",
        "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
        "        \n",
        "        self.W = tf.Variable(rng.uniform(\n",
        "            low=-np.sqrt(6/in_dim),\n",
        "            high=np.sqrt(6/in_dim),\n",
        "            size=(in_dim, out_dim)\n",
        "        ).astype('float32'), name='W')\n",
        "        self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))\n",
        "        self.function = function\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return self.function(tf.matmul(x, self.W) + self.b)\n",
        "    \n",
        "    \n",
        "def tf_log(x):\n",
        "    return tf.log(tf.clip_by_value(x, 1e-10, x))\n",
        "    \n",
        "### ネットワーク ###\n",
        "\n",
        "x_train, x_test, t_train = load_mnist()\n",
        "x_train, x_valid, t_train, t_valid = train_test_split(x_train, t_train, test_size=0.1, random_state=random_state)\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "t = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "h = Conv((5, 5, 1, 20), tf.nn.relu)(x)\n",
        "h = Pooling((1, 2, 2, 1))(h)\n",
        "h = Conv((5, 5, 20, 50), tf.nn.relu)(h)\n",
        "h = Pooling((1, 2, 2, 1))(h)\n",
        "h = Flatten()(h)\n",
        "h = Dense(4*4*50, 200, tf.nn.relu)(h)\n",
        "h = Dense(200, 200, tf.nn.relu)(h)\n",
        "y = Dense(200, 10, tf.nn.softmax)(h)\n",
        "\n",
        "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1))\n",
        "train = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "\n",
        "### 学習 ###\n",
        "\n",
        "n_epochs = 20\n",
        "batch_size = 100\n",
        "n_batches = x_train.shape[0]//batch_size\n",
        "\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    x_train, t_train = shuffle(x_train, t_train)\n",
        "    for batch in range(n_batches):\n",
        "        start = batch * batch_size\n",
        "        end = start + batch_size\n",
        "        sess.run(train, feed_dict={x: x_train[start:end], t: t_train[start:end]})\n",
        "            \n",
        "    y_pred, cost_valid = sess.run([y, cost], feed_dict={x: x_valid, t: t_valid})\n",
        "        \n",
        "    print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
        "        epoch,\n",
        "        cost_valid,\n",
        "        accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "    ))\n",
        "    \n",
        "# y_pred = sess.run(y, feed_dict={x: x_test})\n",
        "# submission = pd.Series(y_pred.argmax(axis=1), name='label')\n",
        "# submission.to_csv('/content/drive/My Drive/lecture_master/2019_summer/deeplearning_matsuo/homework/chap06/submission_pred.csv', header=True, index_label='id')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, Valid Cost: 0.363, Valid Accuracy: 0.864\n",
            "EPOCH: 1, Valid Cost: 0.306, Valid Accuracy: 0.891\n",
            "EPOCH: 2, Valid Cost: 0.315, Valid Accuracy: 0.888\n",
            "EPOCH: 3, Valid Cost: 0.281, Valid Accuracy: 0.897\n",
            "EPOCH: 4, Valid Cost: 0.255, Valid Accuracy: 0.906\n",
            "EPOCH: 5, Valid Cost: 0.281, Valid Accuracy: 0.899\n",
            "EPOCH: 6, Valid Cost: 0.265, Valid Accuracy: 0.908\n",
            "EPOCH: 7, Valid Cost: 0.267, Valid Accuracy: 0.912\n",
            "EPOCH: 8, Valid Cost: 0.295, Valid Accuracy: 0.907\n",
            "EPOCH: 9, Valid Cost: 0.309, Valid Accuracy: 0.902\n",
            "EPOCH: 10, Valid Cost: 0.319, Valid Accuracy: 0.901\n",
            "EPOCH: 11, Valid Cost: 0.325, Valid Accuracy: 0.910\n",
            "EPOCH: 12, Valid Cost: 0.355, Valid Accuracy: 0.905\n",
            "EPOCH: 13, Valid Cost: 0.384, Valid Accuracy: 0.906\n",
            "EPOCH: 14, Valid Cost: 0.366, Valid Accuracy: 0.903\n",
            "EPOCH: 15, Valid Cost: 0.367, Valid Accuracy: 0.909\n",
            "EPOCH: 16, Valid Cost: 0.422, Valid Accuracy: 0.897\n",
            "EPOCH: 17, Valid Cost: 0.446, Valid Accuracy: 0.908\n",
            "EPOCH: 18, Valid Cost: 0.480, Valid Accuracy: 0.899\n",
            "EPOCH: 19, Valid Cost: 0.457, Valid Accuracy: 0.905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxNQxLkql2L6",
        "colab_type": "text"
      },
      "source": [
        "Optimizer: Adam<br>\n",
        "with Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9Lqq1MGbksm",
        "colab_type": "code",
        "outputId": "79296504-2bc2-4fb8-8544-e552580c2d99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rng = np.random.RandomState(1234)\n",
        "random_state = 42\n",
        "\n",
        "### レイヤー定義 ###\n",
        "\n",
        "class Conv:\n",
        "    def __init__(self, filter_shape, function=lambda x: x, strides=[1,1,1,1], padding='VALID'):\n",
        "        \n",
        "        fan_in  = np.prod(filter_shape[:3])\n",
        "        fan_out = np.prod(filter_shape[:2]) * filter_shape[3]\n",
        "        \n",
        "        self.W = tf.Variable(rng.uniform(\n",
        "            low=-np.sqrt(6/fan_in),\n",
        "            high=np.sqrt(6/fan_in),\n",
        "            size=filter_shape\n",
        "        ).astype('float32'), name='W')\n",
        "        self.b = tf.Variable(np.zeros((filter_shape[3]), dtype='float32'), name='b')\n",
        "        self.function = function\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        u = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding) + self.b\n",
        "        return self.function(u)\n",
        "    \n",
        "    \n",
        "class Pooling:\n",
        "    def __init__(self, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID'):\n",
        "        self.ksize = ksize\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return tf.nn.max_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding)\n",
        "    \n",
        "    \n",
        "class Flatten:\n",
        "    def __call__(self, x):\n",
        "        return tf.reshape(x, (-1, np.prod(x.get_shape().as_list()[1:])))\n",
        "    \n",
        "    \n",
        "class Dense:\n",
        "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
        "        \n",
        "        self.W = tf.Variable(rng.uniform(\n",
        "            low=-np.sqrt(6/in_dim),\n",
        "            high=np.sqrt(6/in_dim),\n",
        "            size=(in_dim, out_dim)\n",
        "        ).astype('float32'), name='W')\n",
        "        self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))\n",
        "        self.function = function\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return self.function(tf.matmul(x, self.W) + self.b)\n",
        "    \n",
        "class Dropout:\n",
        "    def __init__(self, dropout_rate=0.0):\n",
        "        self.dropout_rate = dropout_rate\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return tf.cond(\n",
        "            pred=is_training,\n",
        "            true_fn=lambda: tf.nn.dropout(x, rate=self.dropout_rate),\n",
        "            false_fn=lambda: x\n",
        "        )\n",
        "    \n",
        "def tf_log(x):\n",
        "    return tf.log(tf.clip_by_value(x, 1e-10, x))\n",
        "    \n",
        "### ネットワーク ###\n",
        "\n",
        "x_train, x_test, t_train = load_mnist()\n",
        "x_train, x_valid, t_train, t_valid = train_test_split(x_train, t_train, test_size=0.1, random_state=random_state)\n",
        "\n",
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(34)\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "t = tf.placeholder(tf.float32, [None, 10])\n",
        "is_training = tf.placeholder(tf.bool)\n",
        "\n",
        "h = Conv((5, 5, 1, 20), tf.nn.relu)(x)\n",
        "h = Pooling((1, 2, 2, 1))(h)\n",
        "h = Conv((5, 5, 20, 50), tf.nn.relu)(h)\n",
        "h = Pooling((1, 2, 2, 1))(h)\n",
        "h = Flatten()(h)\n",
        "h = Dense(4*4*50, 200, tf.nn.relu)(h)\n",
        "h = Dropout(dropout_rate=0.5)(h)\n",
        "h = Dense(200, 200, tf.nn.relu)(h)\n",
        "h = Dropout(dropout_rate=0.5)(h)\n",
        "y = Dense(200, 10, tf.nn.softmax)(h)\n",
        "\n",
        "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1))\n",
        "train = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "\n",
        "### 学習 ###\n",
        "\n",
        "n_epochs = 20\n",
        "batch_size = 100\n",
        "n_batches = x_train.shape[0]//batch_size\n",
        "\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    x_train, t_train = shuffle(x_train, t_train, random_state=random_state)\n",
        "    for batch in range(n_batches):\n",
        "        start = batch * batch_size\n",
        "        end = start + batch_size\n",
        "        sess.run(train, feed_dict={x: x_train[start:end], t: t_train[start:end], is_training: True})\n",
        "            \n",
        "    y_pred, cost_valid = sess.run([y, cost], feed_dict={x: x_valid, t: t_valid, is_training: False})\n",
        "        \n",
        "    print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
        "        epoch,\n",
        "        cost_valid,\n",
        "        accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "    ))\n",
        "    \n",
        "# y_pred = sess.run(y, feed_dict={x: x_test, is_training: False})\n",
        "# submission = pd.Series(y_pred.argmax(axis=1), name='label')\n",
        "# submission.to_csv('/content/drive/My Drive/lecture_master/2019_summer/deeplearning_matsuo/homework/chap06/submission_pred.csv', header=True, index_label='id')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, Valid Cost: 0.412, Valid Accuracy: 0.849\n",
            "EPOCH: 1, Valid Cost: 0.335, Valid Accuracy: 0.875\n",
            "EPOCH: 2, Valid Cost: 0.309, Valid Accuracy: 0.884\n",
            "EPOCH: 3, Valid Cost: 0.288, Valid Accuracy: 0.892\n",
            "EPOCH: 4, Valid Cost: 0.273, Valid Accuracy: 0.895\n",
            "EPOCH: 5, Valid Cost: 0.261, Valid Accuracy: 0.901\n",
            "EPOCH: 6, Valid Cost: 0.267, Valid Accuracy: 0.902\n",
            "EPOCH: 7, Valid Cost: 0.252, Valid Accuracy: 0.905\n",
            "EPOCH: 8, Valid Cost: 0.257, Valid Accuracy: 0.908\n",
            "EPOCH: 9, Valid Cost: 0.259, Valid Accuracy: 0.908\n",
            "EPOCH: 10, Valid Cost: 0.258, Valid Accuracy: 0.907\n",
            "EPOCH: 11, Valid Cost: 0.267, Valid Accuracy: 0.904\n",
            "EPOCH: 12, Valid Cost: 0.250, Valid Accuracy: 0.910\n",
            "EPOCH: 13, Valid Cost: 0.260, Valid Accuracy: 0.906\n",
            "EPOCH: 14, Valid Cost: 0.274, Valid Accuracy: 0.905\n",
            "EPOCH: 15, Valid Cost: 0.271, Valid Accuracy: 0.906\n",
            "EPOCH: 16, Valid Cost: 0.274, Valid Accuracy: 0.908\n",
            "EPOCH: 17, Valid Cost: 0.269, Valid Accuracy: 0.907\n",
            "EPOCH: 18, Valid Cost: 0.281, Valid Accuracy: 0.910\n",
            "EPOCH: 19, Valid Cost: 0.282, Valid Accuracy: 0.911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2wtCJtj0z9B",
        "colab_type": "text"
      },
      "source": [
        "Optimizer: Adam<br>\n",
        "with l2 normalization<br>\n",
        "with Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fJuB0zelgwo",
        "colab_type": "code",
        "outputId": "dfb9d2aa-3bd6-46c1-989a-912994e9450c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rng = np.random.RandomState(1234)\n",
        "random_state = 42\n",
        "\n",
        "### レイヤー定義 ###\n",
        "\n",
        "class Conv:\n",
        "    def __init__(self, filter_shape, function=lambda x: x, strides=[1,1,1,1], padding='VALID'):\n",
        "        \n",
        "        fan_in  = np.prod(filter_shape[:3])\n",
        "        fan_out = np.prod(filter_shape[:2]) * filter_shape[3]\n",
        "        \n",
        "        self.W = tf.Variable(rng.uniform(\n",
        "            low=-np.sqrt(6/fan_in),\n",
        "            high=np.sqrt(6/fan_in),\n",
        "            size=filter_shape\n",
        "        ).astype('float32'), name='W')\n",
        "        self.b = tf.Variable(np.zeros((filter_shape[3]), dtype='float32'), name='b')\n",
        "        self.function = function\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        \n",
        "        self.params = [self.W, self.b]\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        u = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding) + self.b\n",
        "        return self.function(u)\n",
        "    \n",
        "    \n",
        "class Pooling:\n",
        "    def __init__(self, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID'):\n",
        "        self.ksize = ksize\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        \n",
        "        self.params = []\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return tf.nn.max_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding)\n",
        "    \n",
        "    \n",
        "class Flatten:\n",
        "    def __init__(self):\n",
        "        self.params = []\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return tf.reshape(x, (-1, np.prod(x.get_shape().as_list()[1:])))\n",
        "    \n",
        "    \n",
        "class Dense:\n",
        "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
        "        \n",
        "        self.W = tf.Variable(rng.uniform(\n",
        "            low=-np.sqrt(6/in_dim),\n",
        "            high=np.sqrt(6/in_dim),\n",
        "            size=(in_dim, out_dim)\n",
        "        ).astype('float32'), name='W')\n",
        "        self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))\n",
        "        self.function = function\n",
        "        \n",
        "        self.params = [self.W, self.b]\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return self.function(tf.matmul(x, self.W) + self.b)\n",
        "    \n",
        "class Dropout:\n",
        "    def __init__(self, dropout_rate=0.0):\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.params = []\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return tf.cond(\n",
        "            pred=is_training,\n",
        "            true_fn=lambda: tf.nn.dropout(x, rate=self.dropout_rate),\n",
        "            false_fn=lambda: x\n",
        "        )\n",
        "    \n",
        "def tf_log(x):\n",
        "    return tf.log(tf.clip_by_value(x, 1e-10, x))\n",
        "    \n",
        "def fprops(layers, h):\n",
        "    for layer in layers:\n",
        "        h = layer(h)\n",
        "    return h\n",
        "\n",
        "def get_params(layers):\n",
        "    params_all = []\n",
        "    for layer in layers:\n",
        "        params = layer.params\n",
        "        params_all.extend(params)\n",
        "    return params_all\n",
        "\n",
        "def compute_l2_reg(params):\n",
        "    l2_reg = 0\n",
        "    for param in params:\n",
        "        l2_reg += tf.reduce_sum(tf.square(param))\n",
        "    return l2_reg\n",
        "\n",
        "### ネットワーク ###\n",
        "\n",
        "x_train, x_test, t_train = load_mnist()\n",
        "x_train, x_valid, t_train, t_valid = train_test_split(x_train, t_train, test_size=0.1, random_state=random_state)\n",
        "\n",
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(34)\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "t = tf.placeholder(tf.float32, [None, 10])\n",
        "is_training = tf.placeholder(tf.bool)\n",
        "\n",
        "layers = [\n",
        "    Conv((5, 5, 1, 20), tf.nn.relu),\n",
        "    Pooling((1, 2, 2, 1)),\n",
        "    Conv((5, 5, 20, 50), tf.nn.relu),\n",
        "    Pooling((1, 2, 2, 1)),\n",
        "    Flatten(),\n",
        "    Dense(4*4*50, 200, tf.nn.relu),\n",
        "    Dropout(dropout_rate=0.5),\n",
        "    Dense(200, 200, tf.nn.relu),\n",
        "    Dropout(dropout_rate=0.5),\n",
        "    Dense(200, 10, tf.nn.softmax)\n",
        "]\n",
        "\n",
        "lmd = 1e-4 # l2正則化係数\n",
        "\n",
        "y = fprops(layers, x)\n",
        "params_all = get_params(layers)\n",
        "l2_reg = compute_l2_reg(params_all)\n",
        "\n",
        "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1)) + lmd * l2_reg\n",
        "train = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "\n",
        "### 学習 ###\n",
        "\n",
        "n_epochs = 30\n",
        "batch_size = 100\n",
        "n_batches = x_train.shape[0]//batch_size\n",
        "\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    x_train, t_train = shuffle(x_train, t_train, random_state=random_state)\n",
        "    for batch in range(n_batches):\n",
        "        start = batch * batch_size\n",
        "        end = start + batch_size\n",
        "        sess.run(train, feed_dict={x: x_train[start:end], t: t_train[start:end], is_training: True})\n",
        "            \n",
        "    y_pred, cost_valid = sess.run([y, cost], feed_dict={x: x_valid, t: t_valid, is_training: False})\n",
        "        \n",
        "    print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
        "        epoch,\n",
        "        cost_valid,\n",
        "        accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "    ))\n",
        "    \n",
        "# y_pred = sess.run(y, feed_dict={x: x_test, is_training: False})\n",
        "# submission = pd.Series(y_pred.argmax(axis=1), name='label')\n",
        "# submission.to_csv('/content/drive/My Drive/lecture_master/2019_summer/deeplearning_matsuo/homework/chap06/submission_pred.csv', header=True, index_label='id')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, Valid Cost: 0.491, Valid Accuracy: 0.848\n",
            "EPOCH: 1, Valid Cost: 0.411, Valid Accuracy: 0.875\n",
            "EPOCH: 2, Valid Cost: 0.385, Valid Accuracy: 0.884\n",
            "EPOCH: 3, Valid Cost: 0.360, Valid Accuracy: 0.893\n",
            "EPOCH: 4, Valid Cost: 0.352, Valid Accuracy: 0.898\n",
            "EPOCH: 5, Valid Cost: 0.345, Valid Accuracy: 0.896\n",
            "EPOCH: 6, Valid Cost: 0.333, Valid Accuracy: 0.904\n",
            "EPOCH: 7, Valid Cost: 0.324, Valid Accuracy: 0.906\n",
            "EPOCH: 8, Valid Cost: 0.326, Valid Accuracy: 0.904\n",
            "EPOCH: 9, Valid Cost: 0.336, Valid Accuracy: 0.905\n",
            "EPOCH: 10, Valid Cost: 0.322, Valid Accuracy: 0.908\n",
            "EPOCH: 11, Valid Cost: 0.326, Valid Accuracy: 0.910\n",
            "EPOCH: 12, Valid Cost: 0.330, Valid Accuracy: 0.911\n",
            "EPOCH: 13, Valid Cost: 0.331, Valid Accuracy: 0.909\n",
            "EPOCH: 14, Valid Cost: 0.326, Valid Accuracy: 0.912\n",
            "EPOCH: 15, Valid Cost: 0.340, Valid Accuracy: 0.907\n",
            "EPOCH: 16, Valid Cost: 0.347, Valid Accuracy: 0.907\n",
            "EPOCH: 17, Valid Cost: 0.333, Valid Accuracy: 0.912\n",
            "EPOCH: 18, Valid Cost: 0.334, Valid Accuracy: 0.914\n",
            "EPOCH: 19, Valid Cost: 0.340, Valid Accuracy: 0.911\n",
            "EPOCH: 20, Valid Cost: 0.333, Valid Accuracy: 0.912\n",
            "EPOCH: 21, Valid Cost: 0.331, Valid Accuracy: 0.915\n",
            "EPOCH: 22, Valid Cost: 0.342, Valid Accuracy: 0.917\n",
            "EPOCH: 23, Valid Cost: 0.358, Valid Accuracy: 0.912\n",
            "EPOCH: 24, Valid Cost: 0.346, Valid Accuracy: 0.916\n",
            "EPOCH: 25, Valid Cost: 0.348, Valid Accuracy: 0.915\n",
            "EPOCH: 26, Valid Cost: 0.357, Valid Accuracy: 0.913\n",
            "EPOCH: 27, Valid Cost: 0.360, Valid Accuracy: 0.915\n",
            "EPOCH: 28, Valid Cost: 0.362, Valid Accuracy: 0.915\n",
            "EPOCH: 29, Valid Cost: 0.364, Valid Accuracy: 0.917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6cP9_-i_HB9",
        "colab_type": "text"
      },
      "source": [
        "Optimizer: Adam<br>\n",
        "with Dropout<br>\n",
        "without Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzEDOPm30_3e",
        "colab_type": "code",
        "outputId": "00dcd50e-63e0-4dbc-d158-d88c75e6c182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rng = np.random.RandomState(1234)\n",
        "random_state = 42\n",
        "\n",
        "### レイヤー定義 ###\n",
        "\n",
        "class Conv:\n",
        "    def __init__(self, filter_shape, function=lambda x: x, strides=[1,1,1,1], padding='VALID'):\n",
        "        \n",
        "        fan_in  = np.prod(filter_shape[:3])\n",
        "        fan_out = np.prod(filter_shape[:2]) * filter_shape[3]\n",
        "        \n",
        "        self.W = tf.Variable(rng.uniform(\n",
        "            low=-np.sqrt(6/fan_in),\n",
        "            high=np.sqrt(6/fan_in),\n",
        "            size=filter_shape\n",
        "        ).astype('float32'), name='W')\n",
        "        self.b = tf.Variable(np.zeros((filter_shape[3]), dtype='float32'), name='b')\n",
        "        self.function = function\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        \n",
        "        self.params = [self.W, self.b]\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        u = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding) + self.b\n",
        "        return self.function(u)\n",
        "    \n",
        "    \n",
        "class Pooling:\n",
        "    def __init__(self, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID'):\n",
        "        self.ksize = ksize\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        \n",
        "        self.params = []\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return tf.nn.max_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding)\n",
        "    \n",
        "    \n",
        "class Flatten:\n",
        "    def __init__(self):\n",
        "        self.params = []\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return tf.reshape(x, (-1, np.prod(x.get_shape().as_list()[1:])))\n",
        "    \n",
        "    \n",
        "class Dense:\n",
        "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
        "        \n",
        "        self.W = tf.Variable(rng.uniform(\n",
        "            low=-np.sqrt(6/in_dim),\n",
        "            high=np.sqrt(6/in_dim),\n",
        "            size=(in_dim, out_dim)\n",
        "        ).astype('float32'), name='W')\n",
        "        self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))\n",
        "        self.function = function\n",
        "        \n",
        "        self.params = [self.W, self.b]\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return self.function(tf.matmul(x, self.W) + self.b)\n",
        "    \n",
        "class Dropout:\n",
        "    def __init__(self, dropout_rate=0.0):\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.params = []\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return tf.cond(\n",
        "            pred=is_training,\n",
        "            true_fn=lambda: tf.nn.dropout(x, rate=self.dropout_rate),\n",
        "            false_fn=lambda: x\n",
        "        )\n",
        "    \n",
        "def tf_log(x):\n",
        "    return tf.log(tf.clip_by_value(x, 1e-10, x))\n",
        "    \n",
        "def fprops(layers, h):\n",
        "    for layer in layers:\n",
        "        h = layer(h)\n",
        "    return h\n",
        "\n",
        "def get_params(layers):\n",
        "    params_all = []\n",
        "    for layer in layers:\n",
        "        params = layer.params\n",
        "        params_all.extend(params)\n",
        "    return params_all\n",
        "\n",
        "def compute_l2_reg(params):\n",
        "    l2_reg = 0\n",
        "    for param in params:\n",
        "        l2_reg += tf.reduce_sum(tf.square(param))\n",
        "    return l2_reg\n",
        "\n",
        "### ネットワーク ###\n",
        "\n",
        "x_train, x_test, t_train = load_mnist()\n",
        "x_train, x_valid, t_train, t_valid = train_test_split(x_train, t_train, test_size=0.1, random_state=random_state)\n",
        "\n",
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(34)\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "t = tf.placeholder(tf.float32, [None, 10])\n",
        "is_training = tf.placeholder(tf.bool)\n",
        "\n",
        "layers = [\n",
        "    Conv((5, 5, 1, 20), tf.nn.relu),\n",
        "    # Pooling((1, 2, 2, 1)),\n",
        "    Conv((5, 5, 20, 50), tf.nn.relu),\n",
        "    # Pooling((1, 2, 2, 1)),\n",
        "    Flatten(),\n",
        "    Dense(20*20*50, 200, tf.nn.relu),\n",
        "    Dropout(dropout_rate=0.5),\n",
        "    Dense(200, 200, tf.nn.relu),\n",
        "    Dropout(dropout_rate=0.5),\n",
        "    Dense(200, 10, tf.nn.softmax)\n",
        "]\n",
        "\n",
        "lmd = 1e-3 # l2正則化係数\n",
        "\n",
        "y = fprops(layers, x)\n",
        "params_all = get_params(layers)\n",
        "l2_reg = compute_l2_reg(params_all)\n",
        "\n",
        "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1))\n",
        "train = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "\n",
        "### 学習 ###\n",
        "\n",
        "n_epochs = 30\n",
        "batch_size = 100\n",
        "n_batches = x_train.shape[0]//batch_size\n",
        "\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    x_train, t_train = shuffle(x_train, t_train, random_state=random_state)\n",
        "    for batch in range(n_batches):\n",
        "        start = batch * batch_size\n",
        "        end = start + batch_size\n",
        "        sess.run(train, feed_dict={x: x_train[start:end], t: t_train[start:end], is_training: True})\n",
        "            \n",
        "    y_pred, cost_valid = sess.run([y, cost], feed_dict={x: x_valid, t: t_valid, is_training: False})\n",
        "        \n",
        "    print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
        "        epoch,\n",
        "        cost_valid,\n",
        "        accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "    ))\n",
        "    \n",
        "# y_pred = sess.run(y, feed_dict={x: x_test, is_training: False})\n",
        "# submission = pd.Series(y_pred.argmax(axis=1), name='label')\n",
        "# submission.to_csv('/content/drive/My Drive/lecture_master/2019_summer/deeplearning_matsuo/homework/chap06/submission_pred.csv', header=True, index_label='id')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, Valid Cost: 0.368, Valid Accuracy: 0.869\n",
            "EPOCH: 1, Valid Cost: 0.320, Valid Accuracy: 0.884\n",
            "EPOCH: 2, Valid Cost: 0.285, Valid Accuracy: 0.894\n",
            "EPOCH: 3, Valid Cost: 0.276, Valid Accuracy: 0.898\n",
            "EPOCH: 4, Valid Cost: 0.260, Valid Accuracy: 0.906\n",
            "EPOCH: 5, Valid Cost: 0.262, Valid Accuracy: 0.907\n",
            "EPOCH: 6, Valid Cost: 0.257, Valid Accuracy: 0.908\n",
            "EPOCH: 7, Valid Cost: 0.263, Valid Accuracy: 0.910\n",
            "EPOCH: 8, Valid Cost: 0.279, Valid Accuracy: 0.911\n",
            "EPOCH: 9, Valid Cost: 0.272, Valid Accuracy: 0.911\n",
            "EPOCH: 10, Valid Cost: 0.272, Valid Accuracy: 0.913\n",
            "EPOCH: 11, Valid Cost: 0.289, Valid Accuracy: 0.913\n",
            "EPOCH: 12, Valid Cost: 0.292, Valid Accuracy: 0.909\n",
            "EPOCH: 13, Valid Cost: 0.322, Valid Accuracy: 0.906\n",
            "EPOCH: 14, Valid Cost: 0.323, Valid Accuracy: 0.913\n",
            "EPOCH: 15, Valid Cost: 0.321, Valid Accuracy: 0.910\n",
            "EPOCH: 16, Valid Cost: 0.383, Valid Accuracy: 0.909\n",
            "EPOCH: 17, Valid Cost: 0.372, Valid Accuracy: 0.910\n",
            "EPOCH: 18, Valid Cost: 0.377, Valid Accuracy: 0.912\n",
            "EPOCH: 19, Valid Cost: 0.394, Valid Accuracy: 0.914\n",
            "EPOCH: 20, Valid Cost: 0.389, Valid Accuracy: 0.909\n",
            "EPOCH: 21, Valid Cost: 0.412, Valid Accuracy: 0.906\n",
            "EPOCH: 22, Valid Cost: 0.440, Valid Accuracy: 0.912\n",
            "EPOCH: 23, Valid Cost: 0.406, Valid Accuracy: 0.914\n",
            "EPOCH: 24, Valid Cost: 0.460, Valid Accuracy: 0.908\n",
            "EPOCH: 25, Valid Cost: 0.470, Valid Accuracy: 0.911\n",
            "EPOCH: 26, Valid Cost: 0.443, Valid Accuracy: 0.912\n",
            "EPOCH: 27, Valid Cost: 0.450, Valid Accuracy: 0.909\n",
            "EPOCH: 28, Valid Cost: 0.455, Valid Accuracy: 0.908\n",
            "EPOCH: 29, Valid Cost: 0.491, Valid Accuracy: 0.911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnitQ6Ju9dFW",
        "colab_type": "code",
        "outputId": "c0cb40de-736c-4324-9149-e8d55efd3f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rng = np.random.RandomState(1234)\n",
        "random_state = 42\n",
        "\n",
        "### レイヤー定義 ###\n",
        "\n",
        "class Conv:\n",
        "    def __init__(self, filter_shape, function=lambda x: x, strides=[1,1,1,1], padding='VALID'):\n",
        "        \n",
        "        fan_in  = np.prod(filter_shape[:3])\n",
        "        fan_out = np.prod(filter_shape[:2]) * filter_shape[3]\n",
        "        \n",
        "        self.W = tf.Variable(rng.uniform(\n",
        "            low=-np.sqrt(6/fan_in),\n",
        "            high=np.sqrt(6/fan_in),\n",
        "            size=filter_shape\n",
        "        ).astype('float32'), name='W')\n",
        "        self.b = tf.Variable(np.zeros((filter_shape[3]), dtype='float32'), name='b')\n",
        "        self.function = function\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        \n",
        "        self.params = [self.W, self.b]\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        u = tf.nn.conv2d(x, self.W, strides=self.strides, padding=self.padding) + self.b\n",
        "        return self.function(u)\n",
        "    \n",
        "    \n",
        "class Pooling:\n",
        "    def __init__(self, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID'):\n",
        "        self.ksize = ksize\n",
        "        self.strides = strides\n",
        "        self.padding = padding\n",
        "        \n",
        "        self.params = []\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return tf.nn.max_pool(x, ksize=self.ksize, strides=self.strides, padding=self.padding)\n",
        "    \n",
        "    \n",
        "class Flatten:\n",
        "    def __init__(self):\n",
        "        self.params = []\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return tf.reshape(x, (-1, np.prod(x.get_shape().as_list()[1:])))\n",
        "    \n",
        "    \n",
        "class Dense:\n",
        "    def __init__(self, in_dim, out_dim, function=lambda x: x):\n",
        "        \n",
        "        self.W = tf.Variable(rng.uniform(\n",
        "            low=-np.sqrt(6/in_dim),\n",
        "            high=np.sqrt(6/in_dim),\n",
        "            size=(in_dim, out_dim)\n",
        "        ).astype('float32'), name='W')\n",
        "        self.b = tf.Variable(np.zeros([out_dim]).astype('float32'))\n",
        "        self.function = function\n",
        "        \n",
        "        self.params = [self.W, self.b]\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return self.function(tf.matmul(x, self.W) + self.b)\n",
        "    \n",
        "class Dropout:\n",
        "    def __init__(self, dropout_rate=0.0):\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.params = []\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return tf.cond(\n",
        "            pred=is_training,\n",
        "            true_fn=lambda: tf.nn.dropout(x, rate=self.dropout_rate),\n",
        "            false_fn=lambda: x\n",
        "        )\n",
        "    \n",
        "def tf_log(x):\n",
        "    return tf.log(tf.clip_by_value(x, 1e-10, x))\n",
        "    \n",
        "def fprops(layers, h):\n",
        "    for layer in layers:\n",
        "        h = layer(h)\n",
        "    return h\n",
        "\n",
        "def get_params(layers):\n",
        "    params_all = []\n",
        "    for layer in layers:\n",
        "        params = layer.params\n",
        "        params_all.extend(params)\n",
        "    return params_all\n",
        "\n",
        "def compute_l2_reg(params):\n",
        "    l2_reg = 0\n",
        "    for param in params:\n",
        "        l2_reg += tf.reduce_sum(tf.square(param))\n",
        "    return l2_reg\n",
        "\n",
        "### ネットワーク ###\n",
        "\n",
        "x_train, x_test, t_train = load_mnist()\n",
        "x_train, x_valid, t_train, t_valid = train_test_split(x_train, t_train, test_size=0.1, random_state=random_state)\n",
        "\n",
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(34)\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "t = tf.placeholder(tf.float32, [None, 10])\n",
        "is_training = tf.placeholder(tf.bool)\n",
        "\n",
        "layers = [\n",
        "    Conv((3, 3, 1, 32), tf.nn.relu),\n",
        "    Conv((3, 3, 32, 32), tf.nn.relu),\n",
        "    Pooling((1, 2, 2, 1)),\n",
        "    Dropout(dropout_rate=0.25),\n",
        "    Conv((3, 3, 32, 64), tf.nn.relu),\n",
        "    Conv((3, 3, 64, 64), tf.nn.relu),\n",
        "    Pooling((1, 2, 2, 1)),\n",
        "    Dropout(dropout_rate=0.5),\n",
        "    Flatten(),\n",
        "    Dense(4*4*64, 200, tf.nn.relu),\n",
        "    Dropout(dropout_rate=0.5),\n",
        "    Dense(200, 200, tf.nn.relu),\n",
        "    Dropout(dropout_rate=0.5),\n",
        "    Dense(200, 10, tf.nn.softmax)\n",
        "]\n",
        "\n",
        "lmd = 1e-4 # l2正則化係数\n",
        "\n",
        "y = fprops(layers, x)\n",
        "params_all = get_params(layers)\n",
        "l2_reg = compute_l2_reg(params_all)\n",
        "\n",
        "cost = - tf.reduce_mean(tf.reduce_sum(t * tf_log(y), axis=1)) + lmd * l2_reg\n",
        "train = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "\n",
        "### 学習 ###\n",
        "\n",
        "n_epochs = 60\n",
        "batch_size = 100\n",
        "n_batches = x_train.shape[0]//batch_size\n",
        "\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    x_train, t_train = shuffle(x_train, t_train, random_state=random_state)\n",
        "    for batch in range(n_batches):\n",
        "        start = batch * batch_size\n",
        "        end = start + batch_size\n",
        "        sess.run(train, feed_dict={x: x_train[start:end], t: t_train[start:end], is_training: True})\n",
        "            \n",
        "    y_pred, cost_valid = sess.run([y, cost], feed_dict={x: x_valid, t: t_valid, is_training: False})\n",
        "        \n",
        "    print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n",
        "        epoch,\n",
        "        cost_valid,\n",
        "        accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "    ))\n",
        "    \n",
        "    if accuracy_score(t_valid.argmax(axis=1), y_pred.argmax(axis=1)) >= 0.932:\n",
        "        break\n",
        "    \n",
        "y_pred = sess.run(y, feed_dict={x: x_test, is_training: False})\n",
        "submission = pd.Series(y_pred.argmax(axis=1), name='label')\n",
        "submission.to_csv('/content/drive/My Drive/lecture_master/2019_summer/deeplearning_matsuo/homework/chap06/submission_pred.csv', header=True, index_label='id')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, Valid Cost: 0.633, Valid Accuracy: 0.798\n",
            "EPOCH: 1, Valid Cost: 0.538, Valid Accuracy: 0.841\n",
            "EPOCH: 2, Valid Cost: 0.469, Valid Accuracy: 0.863\n",
            "EPOCH: 3, Valid Cost: 0.422, Valid Accuracy: 0.883\n",
            "EPOCH: 4, Valid Cost: 0.408, Valid Accuracy: 0.883\n",
            "EPOCH: 5, Valid Cost: 0.387, Valid Accuracy: 0.890\n",
            "EPOCH: 6, Valid Cost: 0.373, Valid Accuracy: 0.898\n",
            "EPOCH: 7, Valid Cost: 0.360, Valid Accuracy: 0.904\n",
            "EPOCH: 8, Valid Cost: 0.347, Valid Accuracy: 0.909\n",
            "EPOCH: 9, Valid Cost: 0.343, Valid Accuracy: 0.909\n",
            "EPOCH: 10, Valid Cost: 0.340, Valid Accuracy: 0.911\n",
            "EPOCH: 11, Valid Cost: 0.349, Valid Accuracy: 0.907\n",
            "EPOCH: 12, Valid Cost: 0.335, Valid Accuracy: 0.913\n",
            "EPOCH: 13, Valid Cost: 0.335, Valid Accuracy: 0.914\n",
            "EPOCH: 14, Valid Cost: 0.316, Valid Accuracy: 0.921\n",
            "EPOCH: 15, Valid Cost: 0.317, Valid Accuracy: 0.918\n",
            "EPOCH: 16, Valid Cost: 0.329, Valid Accuracy: 0.918\n",
            "EPOCH: 17, Valid Cost: 0.315, Valid Accuracy: 0.922\n",
            "EPOCH: 18, Valid Cost: 0.320, Valid Accuracy: 0.918\n",
            "EPOCH: 19, Valid Cost: 0.321, Valid Accuracy: 0.921\n",
            "EPOCH: 20, Valid Cost: 0.319, Valid Accuracy: 0.919\n",
            "EPOCH: 21, Valid Cost: 0.321, Valid Accuracy: 0.919\n",
            "EPOCH: 22, Valid Cost: 0.312, Valid Accuracy: 0.925\n",
            "EPOCH: 23, Valid Cost: 0.322, Valid Accuracy: 0.918\n",
            "EPOCH: 24, Valid Cost: 0.309, Valid Accuracy: 0.924\n",
            "EPOCH: 25, Valid Cost: 0.309, Valid Accuracy: 0.927\n",
            "EPOCH: 26, Valid Cost: 0.315, Valid Accuracy: 0.922\n",
            "EPOCH: 27, Valid Cost: 0.316, Valid Accuracy: 0.925\n",
            "EPOCH: 28, Valid Cost: 0.323, Valid Accuracy: 0.921\n",
            "EPOCH: 29, Valid Cost: 0.310, Valid Accuracy: 0.925\n",
            "EPOCH: 30, Valid Cost: 0.310, Valid Accuracy: 0.922\n",
            "EPOCH: 31, Valid Cost: 0.315, Valid Accuracy: 0.927\n",
            "EPOCH: 32, Valid Cost: 0.319, Valid Accuracy: 0.924\n",
            "EPOCH: 33, Valid Cost: 0.313, Valid Accuracy: 0.924\n",
            "EPOCH: 34, Valid Cost: 0.323, Valid Accuracy: 0.920\n",
            "EPOCH: 35, Valid Cost: 0.315, Valid Accuracy: 0.926\n",
            "EPOCH: 36, Valid Cost: 0.303, Valid Accuracy: 0.929\n",
            "EPOCH: 37, Valid Cost: 0.312, Valid Accuracy: 0.928\n",
            "EPOCH: 38, Valid Cost: 0.303, Valid Accuracy: 0.928\n",
            "EPOCH: 39, Valid Cost: 0.309, Valid Accuracy: 0.929\n",
            "EPOCH: 40, Valid Cost: 0.304, Valid Accuracy: 0.930\n",
            "EPOCH: 41, Valid Cost: 0.316, Valid Accuracy: 0.923\n",
            "EPOCH: 42, Valid Cost: 0.312, Valid Accuracy: 0.928\n",
            "EPOCH: 43, Valid Cost: 0.310, Valid Accuracy: 0.930\n",
            "EPOCH: 44, Valid Cost: 0.340, Valid Accuracy: 0.919\n",
            "EPOCH: 45, Valid Cost: 0.311, Valid Accuracy: 0.928\n",
            "EPOCH: 46, Valid Cost: 0.305, Valid Accuracy: 0.930\n",
            "EPOCH: 47, Valid Cost: 0.308, Valid Accuracy: 0.929\n",
            "EPOCH: 48, Valid Cost: 0.304, Valid Accuracy: 0.930\n",
            "EPOCH: 49, Valid Cost: 0.302, Valid Accuracy: 0.931\n",
            "EPOCH: 50, Valid Cost: 0.305, Valid Accuracy: 0.930\n",
            "EPOCH: 51, Valid Cost: 0.307, Valid Accuracy: 0.930\n",
            "EPOCH: 52, Valid Cost: 0.301, Valid Accuracy: 0.933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhtQKhNBK_p_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}